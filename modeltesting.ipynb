{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: generative-ai-hub-sdk in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: panda in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: hana-ml in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (2.23.25021400)\n",
      "Requirement already satisfied: aioboto3 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (14.1.0)\n",
      "Requirement already satisfied: xlsxwriter in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (3.2.3)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (3.13.0)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (8.1.8)\n",
      "Requirement already satisfied: dacite>=1.8.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (1.9.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (0.28.1)\n",
      "Requirement already satisfied: ai-core-sdk>=2.5.7 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (2.5.7)\n",
      "Requirement already satisfied: overloading==0.5.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (0.5.0)\n",
      "Requirement already satisfied: pydantic==2.9.2 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (2.9.2)\n",
      "Requirement already satisfied: openai>=1.56.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (1.65.4)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from generative-ai-hub-sdk) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from pydantic==2.9.2->generative-ai-hub-sdk) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from pydantic==2.9.2->generative-ai-hub-sdk) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from pydantic==2.9.2->generative-ai-hub-sdk) (4.12.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from panda) (65.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from panda) (2.32.3)\n",
      "Requirement already satisfied: hdbcli>=2.18.22 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (2.23.27)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (2.0.2)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (1.2.18)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (4.67.1)\n",
      "Requirement already satisfied: schedule in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (1.2.2)\n",
      "Requirement already satisfied: prettytable in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (3.15.1)\n",
      "Requirement already satisfied: shapely>=1.8.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (2.0.7)\n",
      "Requirement already satisfied: plotly>=4.14.3 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.4 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (2.2.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (2.2.3)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from hana-ml) (3.1.5)\n",
      "Requirement already satisfied: aiobotocore==2.21.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore[boto3]==2.21.1->aioboto3) (2.21.1)\n",
      "Requirement already satisfied: aiofiles>=23.2.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aioboto3) (24.1.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.2 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (3.11.16)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.37.2,>=1.37.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.37.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (2.9.0.post0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (6.4.3)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.17.2)\n",
      "Requirement already satisfied: boto3<1.37.2,>=1.37.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiobotocore[boto3]==2.21.1->aioboto3) (1.37.1)\n",
      "Requirement already satisfied: ai-api-client-sdk==2.4.6 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from ai-core-sdk>=2.5.7->generative-ai-hub-sdk) (2.4.6)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from ai-api-client-sdk==2.4.6->ai-core-sdk>=2.5.7->generative-ai-hub-sdk) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from ai-api-client-sdk==2.4.6->ai-core-sdk>=2.5.7->generative-ai-hub-sdk) (3.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from click>=8.1.7->generative-ai-hub-sdk) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from httpx>=0.27.0->generative-ai-hub-sdk) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->generative-ai-hub-sdk) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from jinja2>=3.0.0->hana-ml) (3.0.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from openai>=1.56.0->generative-ai-hub-sdk) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from openai>=1.56.0->generative-ai-hub-sdk) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from openai>=1.56.0->generative-ai-hub-sdk) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from pandas>=0.24.2->hana-ml) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from pandas>=0.24.2->hana-ml) (2025.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from plotly>=4.14.3->hana-ml) (1.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from requests->panda) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from requests->panda) (2.3.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from prettytable->hana-ml) (0.2.13)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from pydotplus->hana-ml) (3.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.20.0)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from boto3<1.37.2,>=1.37.0->aiobotocore[boto3]==2.21.1->aioboto3) (0.11.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gper\\onedrive - agilita ag\\dokumente\\github\\vektoren\\env\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install generative-ai-hub-sdk panda hana-ml aioboto3 xlsxwriter rapidfuzz\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Customername</th>\n",
       "      <th>Searchterm</th>\n",
       "      <th>Embeddingtext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LLQ Management SA</td>\n",
       "      <td>Lallique, LLQ</td>\n",
       "      <td>LLQ Management SA / LLQ Management / Lalique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CSS Versicherung AG</td>\n",
       "      <td>CSS</td>\n",
       "      <td>CSS Versicherung AG / CSS Versicherung / CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fenaco Genossenschaft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fenaco Genossenschaft / fenaco Genossenschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cc energie sa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cc energie sa / cc energie sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>apsolut GmbH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apsolut GmbH / apsolut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index            Customername     Searchterm  \\\n",
       "0     0       LLQ Management SA  Lallique, LLQ   \n",
       "1     1     CSS Versicherung AG            CSS   \n",
       "2     2   fenaco Genossenschaft            NaN   \n",
       "3     3           cc energie sa            NaN   \n",
       "4     4            apsolut GmbH            NaN   \n",
       "\n",
       "                                       Embeddingtext  \n",
       "0   LLQ Management SA / LLQ Management / Lalique ...  \n",
       "1       CSS Versicherung AG / CSS Versicherung / CSS  \n",
       "2      fenaco Genossenschaft / fenaco Genossenschaft  \n",
       "3                      cc energie sa / cc energie sa  \n",
       "4                             apsolut GmbH / apsolut  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('vectors.xlsx', dtype=str, header=0)\n",
    "df = pd.read_excel('vectors.xlsx', dtype=str)\n",
    "df = df[[\"Index\", \"Customername\", \"Searchterm\", \"Embeddingtext\"]]\n",
    "df = df.dropna(subset=[\"Index\"])\n",
    "df.head(5)\n",
    "df = df.dropna(subset=[\"Index\"])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00.000.00.1744104146 (fa/CE2025.2)\n",
      "DBADMIN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hana_ml import ConnectionContext\n",
    "\n",
    "cc = ConnectionContext(\n",
    "    address=os.environ.get(\"DB_ADDRESS\"),\n",
    "    port=os.environ.get(\"DB_PORT\"),\n",
    "    user=os.environ.get(\"DB_USER\"),\n",
    "    password=os.environ.get(\"DB_PASSWORD\"), \n",
    "    encrypt=True\n",
    ") \n",
    "\n",
    "print(cc.hana_version())\n",
    "print(cc.get_current_schema())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from hana_ml.dataframe import create_dataframe_from_pandas\n",
    "\n",
    "v_hdf = create_dataframe_from_pandas(\n",
    "    connection_context=cc,\n",
    "    pandas_df=df,\n",
    "    table_name=\"DBADMIN.VECTORS\",\n",
    "    allow_bigint=True,\n",
    "    append=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "import time\n",
    "\n",
    "env_vars = {\n",
    "    'AICORE_AUTH_URL' : os.environ.get(\"AICORE_AUTH_URL\"),\n",
    "    'AICORE_CLIENT_ID' : os.environ.get(\"AICORE_CLIENT_ID\"),\n",
    "    'AICORE_CLIENT_SECRET' : os.environ.get(\"AICORE_CLIENT_SECRET\"),\n",
    "    'AICORE_BASE_URL' : os.environ.get(\"AICORE_BASE_URL\"),\n",
    "    'AICORE_RESOURCE_GROUP' : os.environ.get(\"AICORE_RESOURCE_GROUP\"),\n",
    "}\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m     41\u001b[39m     vector_str = row[\u001b[33m'\u001b[39m\u001b[33mEmbeddingtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     model_embeddings = \u001b[43mget_embeddings_for_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_to_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models_to_test:\n\u001b[32m     45\u001b[39m         df.at[index, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEmbedding_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m] = model_embeddings.get(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mget_embeddings_for_models\u001b[39m\u001b[34m(input_text, models)\u001b[39m\n\u001b[32m     16\u001b[39m         result = embeddings.create(model_name=model, \u001b[38;5;28minput\u001b[39m=input_text)\n\u001b[32m     17\u001b[39m         output[model] = result.data[\u001b[32m0\u001b[39m].embedding\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     time.sleep(\u001b[32m0.5\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:                  \n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError with model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from gen_ai_hub.proxy.native.amazon.clients import Session as AmazonSession\n",
    "\n",
    "def get_embeddings_for_models(input_text, models):\n",
    "    output = {}\n",
    "    for model in models:\n",
    "        try:\n",
    "            if model == 'amazon--titan-embed-text':\n",
    "                bedrock = AmazonSession().client(model_name=model)\n",
    "                body = json.dumps({\"inputText\": input_text})\n",
    "                response = bedrock.invoke_model(body=body)\n",
    "                result = json.loads(response.get(\"body\").read())\n",
    "                output[model] = result[\"embedding\"]\n",
    "            else:\n",
    "                result = embeddings.create(model_name=model, input=input_text)\n",
    "                output[model] = result.data[0].embedding\n",
    "\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except Exception as e:                  \n",
    "            print(f\"Error with model {model}: {e}\")\n",
    "            output[model] = None\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Define all supported embedding models\n",
    "models_to_test = [\n",
    "    \"text-embedding-3-small\", \n",
    "    \"text-embedding-3-large\",\n",
    "    \"amazon--titan-embed-text\",\n",
    "]\n",
    "\n",
    "# Create columns for each embedding model\n",
    "for model in models_to_test:\n",
    "    df[f'Embedding_{model}'] = None\n",
    "\n",
    "# Populate the embeddings\n",
    "for index, row in df.iterrows():\n",
    "    vector_str = row['Embeddingtext']\n",
    "    model_embeddings = get_embeddings_for_models(vector_str, models_to_test)\n",
    "\n",
    "    for model in models_to_test:\n",
    "        df.at[index, f'Embedding_{model}'] = model_embeddings.get(model)\n",
    "\n",
    "print(\"Embeddings added for all working models.\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "conn = cc.connection\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for model in models_to_test:\n",
    "        embedding = row.get(f'Embedding_{model}')\n",
    "        if not embedding:\n",
    "            continue\n",
    "\n",
    "        embedding_str = json.dumps(embedding)\n",
    "        customername = row['Customername'] if pd.notna(row['Customername']) else None\n",
    "        searchterm = row['Searchterm'] if pd.notna(row['Searchterm']) else None\n",
    "\n",
    "        merge_sql = \"\"\"\n",
    "            MERGE INTO DBADMIN.VECTORS AS target\n",
    "            USING (SELECT :index AS INDEX, :model AS MODEL FROM DUMMY) AS source\n",
    "            ON target.INDEX = source.INDEX AND target.MODEL = source.MODEL\n",
    "            WHEN MATCHED THEN\n",
    "                UPDATE SET \n",
    "                    CUSTOMERNAME = :customername,\n",
    "                    SEARCHTERM = :searchterm,\n",
    "                    VECTOR = TO_REAL_VECTOR(CAST(:vector AS NVARCHAR)),\n",
    "                    VECTOR_STR = :vector_str\n",
    "            WHEN NOT MATCHED THEN\n",
    "                INSERT (INDEX, CUSTOMERNAME, SEARCHTERM, MODEL, VECTOR, VECTOR_STR)\n",
    "                VALUES (:index, :customername, :searchterm, :model, TO_REAL_VECTOR(CAST(:vector AS NVARCHAR)), :vector_str)\n",
    "        \"\"\"\n",
    "\n",
    "        cursor.execute(merge_sql, {\n",
    "            'index': row[\"Index\"],\n",
    "            'customername': customername,\n",
    "            'searchterm': searchterm,\n",
    "            'model': model,\n",
    "            'vector': embedding_str,\n",
    "            'vector_str': embedding_str\n",
    "        })\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Running vector search for model: text-embedding-3-small\n",
      "🔍 Running vector search for model: text-embedding-3-large\n",
      "🔍 Running vector search for model: amazon--titan-embed-text\n",
      "🔍 Running fuzzy search...\n",
      "✅ All search results saved to: search_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# --- Vector Search ---\n",
    "def run_vector_search(query: str, model: str, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    query_vector = get_embeddings_for_models(query, [model])[model]\n",
    "    if not query_vector:\n",
    "        print(f\"❌ No embedding returned for model: {model}\")\n",
    "        return pd.DataFrame(columns=[\"Index\", \"Customername\", \"Searchterm\", \"Similarity\"])\n",
    "\n",
    "    vector_str = f\"[{','.join(map(str, query_vector))}]\"\n",
    "    sort_order = \"ASC\" if metric == 'L2DISTANCE' else \"DESC\"\n",
    "\n",
    "    sql = f'''\n",
    "    SELECT TOP {k} \n",
    "        Index, Customername, Searchterm, VECTOR,\n",
    "        {metric}(VECTOR, TO_REAL_VECTOR('{vector_str}')) AS Similarity\n",
    "    FROM \"DBADMIN\".\"VECTORS\"\n",
    "    WHERE MODEL = '{model}'\n",
    "    ORDER BY Similarity {sort_order}\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        hdf = cc.sql(sql)\n",
    "        return hdf.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"Error running vector search for model {model}: {e}\")\n",
    "        return pd.DataFrame(columns=[\"Index\", \"Customername\", \"Searchterm\", \"Similarity\"])\n",
    "\n",
    "# --- Fuzzy Search ---\n",
    "def run_fuzzy_search(query, df, text_columns=['Customername', 'Searchterm'], top_k=5, threshold=15):\n",
    "    # Combining text columns into a search_blob for fuzzy matching\n",
    "    df['search_blob'] = df[text_columns].fillna('').agg(' '.join, axis=1)\n",
    "    choices = df['search_blob'].tolist()\n",
    "\n",
    "    # Run fuzzy matching\n",
    "    matches = process.extract(query, choices, scorer=fuzz.token_sort_ratio, limit=top_k)\n",
    "\n",
    "    result_rows = []\n",
    "    for text, score, _ in matches:\n",
    "        if score >= threshold:\n",
    "            idx = choices.index(text)\n",
    "            row = df.iloc[idx][['Index', 'Customername', 'Searchterm']].copy()\n",
    "            row['Similarity'] = score\n",
    "            result_rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(result_rows)\n",
    "\n",
    "# --- Run Search for All Models + Fuzzy ---\n",
    "query = \"Ich habe heute 4 Stunden für BMW die Rollenverteilung der BTP erledigt\"\n",
    "search_results = {}\n",
    "\n",
    "# Run vector searches for each model\n",
    "for model in models_to_test:\n",
    "    print(f\"🔍 Running vector search for model: {model}\")\n",
    "    result_df = run_vector_search(query, model=model)\n",
    "    search_results[f\"Vector_{model}\"] = result_df\n",
    "\n",
    "# Run fuzzy search on the data\n",
    "print(\"🔍 Running fuzzy search...\")\n",
    "search_results[\"Fuzzy_RapidFuzz\"] = run_fuzzy_search(query, df)\n",
    "\n",
    "# --- Save All Results to One Excel File ---\n",
    "excel_filename = \"search_results.xlsx\"\n",
    "with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:\n",
    "    for name, result_df in search_results.items():\n",
    "        sheet_name = name[:31]  # Excel max sheet name length\n",
    "        result_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"✅ All search results saved to: {excel_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
